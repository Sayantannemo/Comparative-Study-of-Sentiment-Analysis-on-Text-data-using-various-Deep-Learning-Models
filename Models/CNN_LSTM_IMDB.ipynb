{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZ1S5AMlLDYh","executionInfo":{"status":"ok","timestamp":1698931128537,"user_tz":-330,"elapsed":2738,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"9b4659fc-cb49-4641-ca2a-327787d3b8f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","source":["import pandas as pd    # to load dataset\n","import numpy as np     # for mathematic equation\n","from nltk.corpus import stopwords   # to get collection of stopwords\n","from sklearn.model_selection import train_test_split       # for splitting dataset\n","from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n","from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n","from tensorflow.keras.models import Sequential     # the model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout,Conv1D,MaxPooling1D # layers of the architecture\n","from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n","from tensorflow.keras.models import load_model   # load saved model\n","import re"],"metadata":{"id":"FQmmwh8hLMvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","english_stops = stopwords.words('english')"],"metadata":{"id":"GdQJaKz8NVmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset():\n","    df = pd.read_csv('IMDB Dataset.csv')\n","    x_data = df['review']       # Reviews/Input\n","    y_data = df['sentiment']    # Sentiment/Output\n","\n","    # PRE-PROCESS REVIEW\n","    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n","    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n","    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words and spliting\n","    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n","\n","    # ENCODE SENTIMENT -> 0 & 1\n","    y_data = y_data.replace('positive', 1)\n","    y_data = y_data.replace('negative', 0)\n","\n","    return x_data, y_data\n","\n","x_data, y_data = load_dataset()\n","\n","print('Reviews')\n","print(x_data, '\\n')\n","print('Sentiment')\n","print(y_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jm5ocgrgLNSp","executionInfo":{"status":"ok","timestamp":1698931588297,"user_tz":-330,"elapsed":34885,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"1a35d532-d59a-4a57-e31c-215d7d67508d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reviews\n","0        [one, reviewers, mentioned, watching, oz, epis...\n","1        [a, wonderful, little, production, the, filmin...\n","2        [i, thought, wonderful, way, spend, time, hot,...\n","3        [basically, family, little, boy, jake, thinks,...\n","4        [petter, mattei, love, time, money, visually, ...\n","                               ...                        \n","49995    [i, thought, movie, right, good, job, it, crea...\n","49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n","49997    [i, catholic, taught, parochial, elementary, s...\n","49998    [i, going, disagree, previous, comment, side, ...\n","49999    [no, one, expects, star, trek, movies, high, a...\n","Name: review, Length: 50000, dtype: object \n","\n","Sentiment\n","0        1\n","1        1\n","2        1\n","3        0\n","4        1\n","        ..\n","49995    1\n","49996    0\n","49997    0\n","49998    0\n","49999    0\n","Name: sentiment, Length: 50000, dtype: int64\n"]}]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n","\n","print('Train Set')\n","print(x_train, '\\n')\n","print(x_test, '\\n')\n","print('Test Set')\n","print(y_train, '\\n')\n","print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qt7s9aqpLWE_","executionInfo":{"status":"ok","timestamp":1698931656549,"user_tz":-330,"elapsed":495,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"2c689ad9-c4ec-4f83-fffd-a3c0389780e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Set\n","40961    [strangers, candy, overacts, wrong, context, s...\n","49012    [this, christopher, guest, movie, rivals, spin...\n","32108    [i, saw, film, edinburgh, film, festival, woul...\n","27671    [one, look, rating, ought, tell, movie, voted,...\n","45688    [i, watched, first, episode, the, war, home, i...\n","                               ...                        \n","13670    [such, highly, anticipated, remake, cherished,...\n","8791     [ok, cons, first, the, obligatory, alligator, ...\n","35733    [my, yardstick, measuring, movie, watch, abili...\n","25444    [i, expecting, love, movie, film, noir, serial...\n","26190    [granny, definitely, one, worst, horror, movie...\n","Name: review, Length: 40000, dtype: object \n","\n","10518    [i, huge, john, denver, fan, i, large, collect...\n","7914     [this, one, would, term, happy, tale, the, tit...\n","21671    [between, twentieth, century, fox, made, ton, ...\n","39727    [surely, best, film, directed, claude, lelouch...\n","2319     [some, films, manage, survive, almost, origina...\n","                               ...                        \n","30940    [so, compromised, this, fairly, charming, film...\n","38271    [it, pretty, clear, director, production, crew...\n","16236    [i, admit, fond, oliver, young, child, long, s...\n","27166    [look, i, know, may, suck, right, pain, tempor...\n","33740    [what, supposed, a, remake, fisher, king, why,...\n","Name: review, Length: 10000, dtype: object \n","\n","Test Set\n","40961    0\n","49012    1\n","32108    0\n","27671    0\n","45688    0\n","        ..\n","13670    0\n","8791     0\n","35733    1\n","25444    0\n","26190    0\n","Name: sentiment, Length: 40000, dtype: int64 \n","\n","10518    1\n","7914     1\n","21671    0\n","39727    1\n","2319     1\n","        ..\n","30940    1\n","38271    0\n","16236    1\n","27166    0\n","33740    0\n","Name: sentiment, Length: 10000, dtype: int64\n"]}]},{"cell_type":"code","source":["def get_max_length():\n","    review_length = []\n","    for review in x_train:\n","        review_length.append(len(review))\n","\n","    return int(np.ceil(np.mean(review_length)))"],"metadata":{"id":"DSbPpFSDLZRg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n","token.fit_on_texts(x_train)\n","x_train = token.texts_to_sequences(x_train)\n","x_test = token.texts_to_sequences(x_test)\n","\n","max_length = get_max_length()\n","\n","x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n","x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n","\n","total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n","\n","print('Encoded X Train\\n', x_train, '\\n')\n","print('Encoded X Test\\n', x_test, '\\n')\n","print('Maximum review length: ', max_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acmO5hWdLbsa","executionInfo":{"status":"ok","timestamp":1698931668456,"user_tz":-330,"elapsed":7250,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"06c58fe6-b3e1-42ee-8022-aba6167f37ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded X Train\n"," [[ 4217  1951  8567 ...     0     0     0]\n"," [    8  1328  2622 ...   399     3   859]\n"," [    1   122     4 ...     0     0     0]\n"," ...\n"," [  219 28483 24779 ...   275   303   364]\n"," [    1   905    41 ...     0     0     0]\n"," [ 7897   313     5 ...     0     0     0]] \n","\n","Encoded X Test\n"," [[   1  538  217 ...    0    0    0]\n"," [   8    5   12 ...  494  240 4126]\n"," [7482 9570  941 ...  930   40  109]\n"," ...\n"," [   1  881 4278 ... 3270  443  752]\n"," [  78    1   47 ...  693 1617 7707]\n"," [ 107  348   39 ...    0    0    0]] \n","\n","Maximum review length:  130\n"]}]},{"cell_type":"code","source":["EMBED_DIM = 32\n","LSTM_OUT = 64\n","FILTER_SIZE = 3\n","NUM_FILTERS = 32\n","POOL_SIZE = 2\n","\n","model = Sequential()\n","\n","# Add a CNN layer\n","model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n","model.add(Conv1D(filters = 64, kernel_size = 3, strides= 1, padding='same', activation= 'relu'))\n","model.add(MaxPooling1D(pool_size=POOL_SIZE))\n","model.add(Dropout(0.2))\n","\n","# Add the LSTM layer\n","model.add(LSTM(LSTM_OUT))\n","model.add(Dropout(0.2))\n","\n","# Add the output layer\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Oc5Fwl4LexK","executionInfo":{"status":"ok","timestamp":1698932044916,"user_tz":-330,"elapsed":1136,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"67c5e73b-37f9-4efc-ac8f-48ec9894aabf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 130, 32)           2957824   \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 130, 64)           6208      \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 65, 64)            0         \n"," g1D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 65, 64)            0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2997121 (11.43 MB)\n","Trainable params: 2997121 (11.43 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["model.fit(x_train, y_train,validation_data=(x_test, y_test), batch_size = 128, epochs = 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XNqaF34LjXx","executionInfo":{"status":"ok","timestamp":1698932237819,"user_tz":-330,"elapsed":191324,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"18e08b85-8efd-410e-e851-178e17dc0781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","313/313 [==============================] - 66s 201ms/step - loss: 0.4690 - accuracy: 0.7351 - val_loss: 0.3123 - val_accuracy: 0.8781\n","Epoch 2/3\n","313/313 [==============================] - 62s 200ms/step - loss: 0.1983 - accuracy: 0.9283 - val_loss: 0.2782 - val_accuracy: 0.8848\n","Epoch 3/3\n","313/313 [==============================] - 62s 200ms/step - loss: 0.0940 - accuracy: 0.9709 - val_loss: 0.3097 - val_accuracy: 0.8854\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f2e48fb2080>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["y_pred =  (model.predict(x_test) > 0.7).astype(\"int32\")\n","\n","true = 0\n","for i, y in enumerate(y_test):\n","    if y == y_pred[i]:\n","        true += 1\n","\n","print('Correct Prediction: {}'.format(true))\n","print('Wrong Prediction: {}'.format(len(y_pred) - true))\n","print('Accuracy: {}'.format(true/len(y_pred)*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTwZdZplLlp5","executionInfo":{"status":"ok","timestamp":1698932279022,"user_tz":-330,"elapsed":5708,"user":{"displayName":"Sayantan Bhattacharyya 23MCA0304","userId":"01953232155221394249"}},"outputId":"12b15e8e-7aef-4492-f556-1ef02e01173e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 5s 15ms/step\n","Correct Prediction: 8769\n","Wrong Prediction: 1231\n","Accuracy: 87.69\n"]}]},{"cell_type":"code","source":["model.save('CNN_LSTM_IMDB_T1.keras')"],"metadata":{"id":"66N7VfIlLoXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model = load_model('CNN_LSTM_IMDB_T1.keras')"],"metadata":{"id":"wEDqowwKLp__"},"execution_count":null,"outputs":[]}]}